{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Master List for ALL Cars\n",
    "\n",
    "This is where you go to bring all car make dataframes together for creating the master dataframes of all cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1:** Unpickle all dfs for all car makes (25 total) \n",
    "\n",
    "Individual car make df must be created and its pickle listed here to bring it into the master car list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acura\n",
    "with open('pickles/acura_dfs.pickle','rb') as read_file:\n",
    "    acura_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audi\n",
    "with open('pickles/audi_dfs.pickle','rb') as read_file:\n",
    "    audi_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BMW\n",
    "with open('pickles/bmw_dfs.pickle','rb') as read_file:\n",
    "    bmw_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bentley\n",
    "with open('pickles/bentley_dfs.pickle','rb') as read_file:\n",
    "    bentley_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bugatti\n",
    "with open('pickles/bugatti_dfs.pickle','rb') as read_file:\n",
    "    bugatti_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buick\n",
    "with open('pickles/buick_dfs.pickle','rb') as read_file:\n",
    "    buick_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cadillac\n",
    "with open('pickles/cadillac_dfs.pickle','rb') as read_file:\n",
    "    cadillac_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chevrolet\n",
    "with open('pickles/chevrolet_dfs.pickle','rb') as read_file:\n",
    "    chevrolet_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chrysler\n",
    "with open('pickles/chrysler_dfs.pickle','rb') as read_file:\n",
    "    chrysler_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dodge\n",
    "with open('pickles/dodge_dfs.pickle','rb') as read_file:\n",
    "    dodge_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ford\n",
    "with open('pickles/ford_dfs.pickle','rb') as read_file:\n",
    "    ford_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GMC\n",
    "with open('pickles/gmc_dfs.pickle','rb') as read_file:\n",
    "    gmc_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Honda\n",
    "with open('pickles/honda_dfs.pickle','rb') as read_file:\n",
    "    honda_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaguar\n",
    "with open('pickles/jaguar_dfs.pickle','rb') as read_file:\n",
    "    jaguar_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jeep\n",
    "with open('pickles/jeep_dfs.pickle','rb') as read_file:\n",
    "    jeep_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maserati\n",
    "with open('pickles/maserati_dfs.pickle','rb') as read_file:\n",
    "    maserati_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mazda\n",
    "with open('pickles/mazda_dfs.pickle','rb') as read_file:\n",
    "    mazda_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mercedes-Benz\n",
    "with open('pickles/mercedes_dfs.pickle','rb') as read_file:\n",
    "    mercedes_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mitsubishi\n",
    "with open('pickles/mitsubishi_dfs.pickle','rb') as read_file:\n",
    "    mitsubishi_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nissan\n",
    "with open('pickles/nissan_dfs.pickle','rb') as read_file:\n",
    "    nissan_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Porsche\n",
    "with open('pickles/porsche_dfs.pickle','rb') as read_file:\n",
    "    porsche_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subaru\n",
    "with open('pickles/subaru_dfs.pickle','rb') as read_file:\n",
    "    subaru_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toyota\n",
    "with open('pickles/toyota_dfs.pickle','rb') as read_file:\n",
    "    toyota_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volkswagen\n",
    "with open('pickles/volkswagen_dfs.pickle','rb') as read_file:\n",
    "    volkswagen_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volvo\n",
    "with open('pickles/volvo_dfs.pickle','rb') as read_file:\n",
    "    volvo_dfs = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2:** Pull all unpickled dfs together to create final list of all cars! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of all car makes' dfs\n",
    "make_dfs = [acura_dfs,\n",
    "            audi_dfs,\n",
    "            bmw_dfs,\n",
    "            bentley_dfs,\n",
    "            bugatti_dfs,\n",
    "            buick_dfs,\n",
    "            cadillac_dfs,\n",
    "            chevrolet_dfs,\n",
    "            chrysler_dfs,\n",
    "            dodge_dfs,\n",
    "            ford_dfs,\n",
    "            gmc_dfs,\n",
    "            honda_dfs,\n",
    "            jaguar_dfs,\n",
    "            jeep_dfs,\n",
    "            maserati_dfs,\n",
    "            mazda_dfs,\n",
    "            mercedes_dfs,\n",
    "            mitsubishi_dfs,\n",
    "            nissan_dfs,\n",
    "            porsche_dfs,\n",
    "            subaru_dfs,\n",
    "            toyota_dfs,\n",
    "            volkswagen_dfs,\n",
    "            volvo_dfs\n",
    "           ]\n",
    "\n",
    "# concatendate all car makes' dfs to create master list\n",
    "all_cars_df = pd.concat(make_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find size of master dataframe just created above >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5265, 10)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cars_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pickle it & create a csv for ease to pull and reference moving forward >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cars_df.to_csv('all_cars_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/all_cars_df.pickle', 'wb') as to_write:\n",
    "    pickle.dump(all_cars_df, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3:** Clean up values in dataframe as needed to prepare for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first un-pickle to get master dataframe of all cars made above\n",
    "\n",
    "with open('pickles/all_cars_df.pickle','rb') as read_file:\n",
    "    all_cars_df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5265 entries, 0 to 5264\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   year             5265 non-null   float64\n",
      " 1   make             5265 non-null   object \n",
      " 2   model            5265 non-null   object \n",
      " 3   capacity_liters  5265 non-null   float64\n",
      " 4   cylinders        5265 non-null   float64\n",
      " 5   transmission     5265 non-null   object \n",
      " 6   trans_speed      5265 non-null   object \n",
      " 7   fuel_type        5265 non-null   object \n",
      " 8   gg_emissions     5265 non-null   float64\n",
      " 9   mpg              5265 non-null   float64\n",
      "dtypes: float64(5), object(5)\n",
      "memory usage: 411.5+ KB\n"
     ]
    }
   ],
   "source": [
    "all_cars_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digit Types - year, capacity_liters, cylinders, gg_emissions, and mpg should all be numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`year` are `cylinders` are float, but will change to integer clean -- later dummies will be created for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cars_df['year'] = all_cars_df.year.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cars_df['cylinders'] = all_cars_df.cylinders.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Space needs to be stripped in `fuel_types` names >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_cars_df['fuel_type'] = all_cars_df.fuel_type.str.strip(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of values for capacity liters -- may want to try bucketing them for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2, 2.3, 3.2, 3. , 1.5, 2.4, 2. , 1.6, 1.8, 2.5, 2.7, 3.5, 3.7,\n",
       "       2.8, 2.1, 5.2, 4.2, 2.9, 4. , 3.6, 4.4, 1.9, 4.9, 6.8, 6.7, 8. ,\n",
       "       4.3, 3.8, 3.1, 5.7, 5. , 1.3, 1.4, 1.2, 5.3, 3.4, 4.1, 4.5, 4.6,\n",
       "       6. , 6.2, 6.5, 1. , 3.3, 2.6, 3.9, 5.9, 8.4, 5.4, 4.7, 5.6, 5.5,\n",
       "       1.7])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cars_df.capacity_liters.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have over 1000 models of cars, so this will likely be left out of analysis -- there are too many comparied to overall dataset size and would not be of value in the model as it doesn't affect the mechanics of the car that create greeenhouse gas emissions (the 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1083"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_cars_df.model.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'y' value (greenhouse gas emissions from tailpipe of car >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 337 values of actual greenhouse gas emissions -- the \"y\" values.\n",
      "The values for the greenhouse gas emissions range from 168.0 to  889.0\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(all_cars_df.gg_emissions.unique())} values of actual greenhouse gas emissions -- the \"y\" values.')\n",
    "print(f'The values for the greenhouse gas emissions range from {all_cars_df.gg_emissions.min()} to  {all_cars_df.gg_emissions.max()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed basics of cleaning up data -- now pickle this dataframe and rename as `all_cars_eda` to then pull in new notebook `all_cars_gge_model.ipynb`, and that's the next file we'll go to to continue with Exploratory Data Analysis and to build a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/all_cars_eda.pickle', 'wb') as to_write:\n",
    "    pickle.dump(all_cars_df, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
